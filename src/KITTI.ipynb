{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização do Dataset KITTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "cv2.cuda.getCudaEnabledDeviceCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config.json file\n",
    "config = json.load(open('./config.json'))\n",
    "KITTI_path = config[\"KITTI\"][\"path\"]\n",
    "sequences_path  = KITTI_path + config[\"KITTI\"][\"sequences path\"]\n",
    "poses_path      = KITTI_path + config[\"KITTI\"][\"poses_path\"]\n",
    "num_sequences   = config[\"KITTI\"][\"num_sequences\"]\n",
    "num_poses       = config[\"KITTI\"][\"num_poses\"]\n",
    "\n",
    "print(\"KITTI path: \", KITTI_path)\n",
    "print(\"Sequences path: \", sequences_path)\n",
    "print(\"Poses path: \", poses_path)\n",
    "print(\"Number of sequences: \", num_sequences)\n",
    "print(\"Number of poses: \", num_poses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load poses\n",
    "poses = [pd.read_csv('{}/{:02}.txt'.format(poses_path, i), delimiter=' ', header=None) for i in range(num_poses)]\n",
    "poses[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the ground truth poses into a list of numpy arrays\n",
    "# Then, we do the dot product between the poses and (0, 0, 0, 1) to get the \n",
    "# postiion of the camera in relation to it's first position (0, 0, 0)\n",
    "\n",
    "gt = []\n",
    "for i in range(len(poses)):\n",
    "    gt.append(np.zeros((len(poses[i]), 3, 4)))\n",
    "    for j in range(len(poses[i])):\n",
    "        gt[i][j] = np.array(poses[i].iloc[j]).reshape((3, 4))\n",
    "\n",
    "gtv = []\n",
    "for i in range(len(poses)):\n",
    "    gtv.append(np.zeros((len(poses[i]), 3)))\n",
    "    for j in range(len(poses[i])):\n",
    "        gtv[i][j] = gt[i][j].dot(np.array([0,0,0,1]))\n",
    "\n",
    "print(gt[0][1].dot(np.array([0,0,0,1])))\n",
    "print(gt[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trajectory demonstration\n",
    "\n",
    "fig = plt.figure(figsize=(7,6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot(gtv[0][:,0], gtv[0][:,1], gtv[0][:,2], label='Ground Truth')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('z')\n",
    "ax.view_init(elev = -40, azim = 270)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstração da relação entre coordenadas em pixel $u, v$ e coordenadas em metros $x, y, z$.\n",
    "- $\\lambda = $ escala de profundidade.\n",
    "- $K = $ matriz de calibração intrínseca.\n",
    "- $R = $ matriz de rotação.\n",
    "- $t = $ vetor de translação.\n",
    "\n",
    "![Projection Matrix](../resources/intrinsic_extrinsic.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = pd.read_csv(sequences_path + '/00/calib.txt', delimiter=' ', header=None, index_col=0)\n",
    "cb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = pd.read_csv(sequences_path + '/00/times.txt', delimiter=' ', header=None, index_col=0)\n",
    "ti.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read calibration and times files for each sequence\n",
    "camera_calib = []\n",
    "time_stamps  = []\n",
    "for i in range(num_sequences):\n",
    "    cb = pd.read_csv(sequences_path + '/{:02}/calib.txt'.format(i), delimiter=' ', header=None, index_col=0).loc['P0:']\n",
    "    ti = pd.read_csv(sequences_path + '/{:02}/times.txt'.format(i), delimiter=' ', header=None)\n",
    "    camera_calib.append(np.array(cb).reshape((3, 4))[0:3, 0:3])\n",
    "    time_stamps.append(np.array(ti))\n",
    "camera_calib = np.array(camera_calib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import main\n",
    "seq_name = '00'\n",
    "seq_idx  = int(seq_name)\n",
    "preffered_direction = 2\n",
    "main.run_KITTI_visual_odometry(sequences_path, seq_name, seq_idx, gt[seq_idx], camera_calib[seq_idx], time_stamps[seq_idx], preffered_direction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
